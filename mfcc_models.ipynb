{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# feature extractoring and preprocessing data\n",
    "import librosa\n",
    "import librosa.display\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import csv\n",
    "# Preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from scipy import signal\n",
    "import scipy\n",
    "#Reports\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "import pydub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_path = Path('/media/sasanka/Expansion/xeno-canto-bird-recordings-extended-a-m/A-M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr = 32000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3954\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('./train_extended.csv')\n",
    "# Selecting high-rated sound only\n",
    "dff = df[df['rating'] > 3.0]\n",
    "# Selecting shorter files only, less data to process\n",
    "dff = dff[df['duration'] < 20]\n",
    "print(len(dff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2967\n"
     ]
    }
   ],
   "source": [
    "# Selecting birds with more than 10 examples left\n",
    "dfc = dff.groupby('ebird_code')['ebird_code'].count()\n",
    "dff = dff[~dff['ebird_code'].isin(dfc[dfc.values < 20].index)]\n",
    "print(len(dff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sound_categories = dff['ebird_code'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['amecro', 'amerob', 'barswa', 'bewwre', 'blujay', 'bnhcow',\n",
       "       'cangoo', 'carwre', 'caster1', 'chispa', 'comrav', 'comred',\n",
       "       'comter', 'comyel', 'daejun', 'easmea', 'eastow', 'eucdov',\n",
       "       'eursta', 'gadwal', 'gnwtea', 'greegr', 'grtgra', 'grycat',\n",
       "       'horlar', 'houfin', 'houspa', 'houwre', 'mallar3', 'marwre',\n",
       "       'norcar', 'norfli', 'normoc', 'redcro', 'rewbla', 'savspa',\n",
       "       'sonspa', 'spotow', 'swathr', 'tuftit', 'warvir', 'wesmea',\n",
       "       'whtspa'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sound_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfcc_df = pd.DataFrame([], columns = ['ebird_code', 'mfcc_mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cd55d3b797743cea2209eecc8620c7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/43 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bird: amecro  files: 33\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [45], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     13\u001b[0m     sound_path \u001b[39m=\u001b[39m audio_path\u001b[39m/\u001b[39mcategory_name\u001b[39m/\u001b[39mfile_name\n\u001b[0;32m---> 14\u001b[0m     y, sr \u001b[39m=\u001b[39m librosa\u001b[39m.\u001b[39;49mload(sound_path, mono\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, sr\u001b[39m=\u001b[39;49msr)\n\u001b[1;32m     15\u001b[0m     mfcc \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmean(librosa\u001b[39m.\u001b[39mfeature\u001b[39m.\u001b[39mmfcc(y\u001b[39m=\u001b[39my, sr\u001b[39m=\u001b[39msr, n_mfcc\u001b[39m=\u001b[39m\u001b[39m13\u001b[39m)\u001b[39m.\u001b[39mT,axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m     16\u001b[0m     audios\u001b[39m.\u001b[39mappend((category_name,mfcc))\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/classifier-6kmiv1wi/lib/python3.10/site-packages/librosa/util/decorators.py:88\u001b[0m, in \u001b[0;36mdeprecate_positional_args.<locals>._inner_deprecate_positional_args.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m extra_args \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(args) \u001b[39m-\u001b[39m \u001b[39mlen\u001b[39m(all_args)\n\u001b[1;32m     87\u001b[0m \u001b[39mif\u001b[39;00m extra_args \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m---> 88\u001b[0m     \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     90\u001b[0m \u001b[39m# extra_args > 0\u001b[39;00m\n\u001b[1;32m     91\u001b[0m args_msg \u001b[39m=\u001b[39m [\n\u001b[1;32m     92\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(name, arg)\n\u001b[1;32m     93\u001b[0m     \u001b[39mfor\u001b[39;00m name, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(kwonly_args[:extra_args], args[\u001b[39m-\u001b[39mextra_args:])\n\u001b[1;32m     94\u001b[0m ]\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/classifier-6kmiv1wi/lib/python3.10/site-packages/librosa/core/audio.py:179\u001b[0m, in \u001b[0;36mload\u001b[0;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[1;32m    176\u001b[0m     y \u001b[39m=\u001b[39m to_mono(y)\n\u001b[1;32m    178\u001b[0m \u001b[39mif\u001b[39;00m sr \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 179\u001b[0m     y \u001b[39m=\u001b[39m resample(y, orig_sr\u001b[39m=\u001b[39;49msr_native, target_sr\u001b[39m=\u001b[39;49msr, res_type\u001b[39m=\u001b[39;49mres_type)\n\u001b[1;32m    181\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    182\u001b[0m     sr \u001b[39m=\u001b[39m sr_native\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/classifier-6kmiv1wi/lib/python3.10/site-packages/librosa/util/decorators.py:88\u001b[0m, in \u001b[0;36mdeprecate_positional_args.<locals>._inner_deprecate_positional_args.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m extra_args \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(args) \u001b[39m-\u001b[39m \u001b[39mlen\u001b[39m(all_args)\n\u001b[1;32m     87\u001b[0m \u001b[39mif\u001b[39;00m extra_args \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m---> 88\u001b[0m     \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     90\u001b[0m \u001b[39m# extra_args > 0\u001b[39;00m\n\u001b[1;32m     91\u001b[0m args_msg \u001b[39m=\u001b[39m [\n\u001b[1;32m     92\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(name, arg)\n\u001b[1;32m     93\u001b[0m     \u001b[39mfor\u001b[39;00m name, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(kwonly_args[:extra_args], args[\u001b[39m-\u001b[39mextra_args:])\n\u001b[1;32m     94\u001b[0m ]\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/classifier-6kmiv1wi/lib/python3.10/site-packages/librosa/core/audio.py:647\u001b[0m, in \u001b[0;36mresample\u001b[0;34m(y, orig_sr, target_sr, res_type, fix, scale, **kwargs)\u001b[0m\n\u001b[1;32m    645\u001b[0m     y_hat \u001b[39m=\u001b[39m soxr\u001b[39m.\u001b[39mresample(y\u001b[39m.\u001b[39mT, orig_sr, target_sr, quality\u001b[39m=\u001b[39mres_type)\u001b[39m.\u001b[39mT\n\u001b[1;32m    646\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 647\u001b[0m     y_hat \u001b[39m=\u001b[39m resampy\u001b[39m.\u001b[39;49mresample(y, orig_sr, target_sr, \u001b[39mfilter\u001b[39;49m\u001b[39m=\u001b[39;49mres_type, axis\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m    649\u001b[0m \u001b[39mif\u001b[39;00m fix:\n\u001b[1;32m    650\u001b[0m     y_hat \u001b[39m=\u001b[39m util\u001b[39m.\u001b[39mfix_length(y_hat, size\u001b[39m=\u001b[39mn_samples, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/classifier-6kmiv1wi/lib/python3.10/site-packages/resampy/core.py:168\u001b[0m, in \u001b[0;36mresample\u001b[0;34m(x, sr_orig, sr_new, axis, filter, parallel, **kwargs)\u001b[0m\n\u001b[1;32m    158\u001b[0m         resample_f_s(\n\u001b[1;32m    159\u001b[0m             x\u001b[39m.\u001b[39mswapaxes(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, axis),\n\u001b[1;32m    160\u001b[0m             t_out,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    165\u001b[0m             y\u001b[39m.\u001b[39mswapaxes(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, axis),\n\u001b[1;32m    166\u001b[0m         )\n\u001b[1;32m    167\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 168\u001b[0m     resample_f_s(\n\u001b[1;32m    169\u001b[0m         x\u001b[39m.\u001b[39;49mswapaxes(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, axis),\n\u001b[1;32m    170\u001b[0m         t_out,\n\u001b[1;32m    171\u001b[0m         interp_win,\n\u001b[1;32m    172\u001b[0m         interp_delta,\n\u001b[1;32m    173\u001b[0m         precision,\n\u001b[1;32m    174\u001b[0m         scale,\n\u001b[1;32m    175\u001b[0m         y\u001b[39m.\u001b[39;49mswapaxes(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, axis),\n\u001b[1;32m    176\u001b[0m     )\n\u001b[1;32m    178\u001b[0m \u001b[39mreturn\u001b[39;00m y\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/classifier-6kmiv1wi/lib/python3.10/site-packages/numba/np/ufunc/gufunc.py:192\u001b[0m, in \u001b[0;36mGUFunc.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    190\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madd(sig)\n\u001b[1;32m    191\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuild_ufunc()\n\u001b[0;32m--> 192\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mufunc(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "audios = []\n",
    "Y = []\n",
    "Y_classes = []\n",
    "label = 0\n",
    "category_progress = tqdm(sound_categories)\n",
    "for category_name in category_progress:\n",
    "    category_progress.desc = category_name\n",
    "    #Walk through the dataframe filename values\n",
    "    l_files = dff[dff['ebird_code'] == category_name]['filename'].values\n",
    "    tqdm.write(\"Bird: \"+category_name+\"  files: \"+str(len(l_files)))\n",
    "    for file_name in l_files:\n",
    "        try:\n",
    "            sound_path = audio_path/category_name/file_name\n",
    "            y, sr = librosa.load(sound_path, mono=True, sr=sr)\n",
    "            mfcc = np.mean(librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13).T,axis=0)\n",
    "            audios.append((category_name,mfcc))\n",
    "        except Exception as e:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>playback_used</th>\n",
       "      <th>ebird_code</th>\n",
       "      <th>channels</th>\n",
       "      <th>date</th>\n",
       "      <th>duration</th>\n",
       "      <th>filename</th>\n",
       "      <th>species</th>\n",
       "      <th>title</th>\n",
       "      <th>secondary_labels</th>\n",
       "      <th>...</th>\n",
       "      <th>background</th>\n",
       "      <th>xc_id</th>\n",
       "      <th>url</th>\n",
       "      <th>country</th>\n",
       "      <th>author</th>\n",
       "      <th>primary_label</th>\n",
       "      <th>longitude</th>\n",
       "      <th>time</th>\n",
       "      <th>recordist</th>\n",
       "      <th>license</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [rating, playback_used, ebird_code, channels, date, duration, filename, species, title, secondary_labels, bird_seen, sci_name, location, latitude, sampling_rate, type, elevation, bitrate_of_mp3, file_type, background, xc_id, url, country, author, primary_label, longitude, time, recordist, license]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 29 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[:-1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('classifier-6kmiv1wi')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "301c2243a5f978eb8d0b3cbdd508660e93a1295d21275fecc963b64e41b6887b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
